{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f747a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.insert(0, '..')\n",
    "from datasets import ShapeNetDataset, PointCloudNormalize\n",
    "from torch.utils.data import DataLoader\n",
    "from models import PointNet\n",
    "import torch.nn.functional as F\n",
    "import k3d\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from distinctipy import distinctipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a906b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_projector(x, model, layer_idx):\n",
    "    batch_size, dim, n_points = x.shape\n",
    "    x = x.transpose(2, 1).contiguous().view(-1, dim)\n",
    "    x = model.mlp(x, idx=layer_idx).contiguous().view(batch_size, n_points, -1).transpose(2, 1)\n",
    "    return x\n",
    "\n",
    "def center(points):\n",
    "    out = points.clone()\n",
    "    '''y = points[:, 1, :].clone()\n",
    "    out[:, 1, :] = points[:, 2, :].clone()\n",
    "    out[:, 2, :] = y'''\n",
    "    return out.transpose(2, 1).numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_features(model, x, layer_idx=-1):\n",
    "    model.eval()\n",
    "    features = model.forward_features(x)\n",
    "    proj = apply_projector(features, model, layer_idx)\n",
    "    proj = F.normalize(proj, dim=1)\n",
    "\n",
    "    return proj\n",
    "\n",
    "def get_similarity_scores(features, query_sample_idx, query_point_idx, support_sample_idx):\n",
    "    q_feat = features[query_sample_idx, :, query_point_idx]\n",
    "    s_feats = features[support_sample_idx]\n",
    "    \n",
    "    return (q_feat @ s_feats).cpu()\n",
    "    \n",
    "\n",
    "def convert_labels2colors(labels):\n",
    "    colors = np.zeros((labels.shape[0], labels.shape[1], 3))\n",
    "\n",
    "    for i in range(labels.shape[0]):\n",
    "        for j in range(labels.shape[1]):\n",
    "            colors[i, j] = sem_palette[labels[i, j]][:3]\n",
    "            \n",
    "    return colors\n",
    "\n",
    "sem_palette = np.array(distinctipy.get_colors(70, pastel_factor=0.2))\n",
    "# sem_palette = np.load('../vis/palette.npy')\n",
    "sim_palette = sns.color_palette(\"plasma\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f523de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset = ShapeNetDataset('../../datasets/hdfs/shapenet.h5', ['val'], ['all'],\n",
    "                                     points_labels_path='../../datasets/shapenet_labels_global.h5',\n",
    "                                     transform=PointCloudNormalize('box'),\n",
    "                                     point_labels_level='local',\n",
    "                                     n_classes=50)\n",
    "\n",
    "dataset = ShapeNetDataset('../../datasets/hdfs/shapenet.h5', ['val'], ['all'],\n",
    "                          points_labels_path='../../datasets/shapenet_labels_global.h5',\n",
    "                          point_labels_level='local',\n",
    "                          n_classes=70)\n",
    "\n",
    "loader = DataLoader(normalized_dataset, shuffle=False, batch_size=4)\n",
    "un_loader = DataLoader(dataset, shuffle=False, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a96e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "model = PointNet().to(device)\n",
    "model.load_state_dict(torch.load('../weights/simclr_run_1kindykb_ckp_150.pt', map_location=device)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbf74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ede4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_query_point(colors):\n",
    "    red = np.array([220 / 255, 27 / 255, 27 / 255])\n",
    "    \n",
    "    for i in range(colors.shape[0]):\n",
    "        if np.allclose(colors[i], red):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024dde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('../vis/activations_all/headphones_arc.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fa26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_query_point(d['colors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90197f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, l0 = normalized_dataset[2]\n",
    "x1, l1 = normalized_dataset[5]\n",
    "\n",
    "x2, l2 = normalized_dataset[1204]\n",
    "x3, l3 = normalized_dataset[1205]\n",
    "\n",
    "x4, l4 = normalized_dataset[1520]\n",
    "x5, l5 = normalized_dataset[1519]\n",
    "\n",
    "x = torch.from_numpy(np.array([x0, x1, x2, x3, x4, x5]))\n",
    "labels = torch.from_numpy(np.array([l0, l1, l2, l3, l4, l5]))\n",
    "device = 'cuda:2'\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32c0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_dataset = ShapeNetDataset('../../datasets/hdfs/shapenet.h5', ['val'], ['all'],\n",
    "                             points_labels_path='../../datasets/shapenet_labels_global.h5',\n",
    "                             point_labels_level='global',\n",
    "                             n_classes=70)\n",
    "\n",
    "x0, l0 = normalized_dataset[2]\n",
    "x1, l1 = normalized_dataset[5]\n",
    "x2, l2 = normalized_dataset[6]\n",
    "x3, l3 = normalized_dataset[7]\n",
    "labels = torch.from_numpy(np.array([l0, l1, l2, l3]))\n",
    "x = torch.from_numpy(np.array([x0, x1, x2, x3]))\n",
    "\n",
    "global_labels = np.array([gl_dataset[2][1], gl_dataset[5][1], gl_dataset[6][1], gl_dataset[7][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5378713",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = np.full((4, 2048, 3), 134 / 255)\n",
    "colors = np.concatenate([grey, sem_palette[labels], sem_palette[global_labels]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04f0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.concatenate([x.transpose(2, 1).cpu().numpy(), x.transpose(2, 1).cpu().numpy(),\n",
    "                         x.transpose(2, 1).cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3d.points(x[0].cpu().t(), attribute=labels[0], point_size=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85817a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_features(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc716397",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = k3d.plot()\n",
    "\n",
    "query_sample_idx = 6\n",
    "query_point_idx = 117\n",
    "support_sample_idx = 7\n",
    "\n",
    "\n",
    "sim = get_similarity_scores(feats, query_sample_idx, query_point_idx, support_sample_idx)\n",
    "\n",
    "y = x[query_sample_idx].clone()\n",
    "y[1] += 2\n",
    "pl += k3d.points(y.cpu().t(), point_size=0.08)\n",
    "pl += k3d.points(y[:, query_point_idx:query_point_idx+1].cpu().t(), point_size=0.2)\n",
    "pl += k3d.points(x[support_sample_idx].cpu().t(), point_size=0.08, attribute=sim)\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5263764",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = np.full((2048, 3), 134 / 255)\n",
    "grey[query_point_idx] = [220 / 255, 27 / 255, 27 / 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd95777",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../vis/algo_ex', points=points, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7361333",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([grey, sim_palette(sim.numpy())[:, :3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e038b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../vis/headphones_arc', points=x[6:8].transpose(2, 1).cpu(), colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ab1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "airplane, airplane_labels = dataset[0]\n",
    "airplane2, airplane2_labels = dataset[2]\n",
    "\n",
    "chair, chair_labels = dataset[2011]\n",
    "chair2, chair2_labels = dataset[2013]\n",
    "\n",
    "car, car_labels = dataset[1161]\n",
    "car2, car2_labels = dataset[1169]\n",
    "\n",
    "labels = np.array([airplane_labels, airplane2_labels, chair_labels, chair2_labels, car_labels, car2_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e07c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npz')\n",
    "points = data['points']\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85812bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = convert_labels2colors(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3d.points((points @ r)[0], point_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(car_labels), set(car2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.transpose(np.array([airplane, airplane2, chair, chair2, car, car2]), (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../vis/patches_spectral.npz', colors=colors, points=points @ r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../vis/patches.npz', colors=colors, points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(chair2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d556aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3d.points(car2.T, attribute=car2_labels, point_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db58061",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaaba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install distinctipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../vis/palette', sem_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb7954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
